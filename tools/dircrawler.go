package tools

import (
	"fmt"
	"net/http"

	"github.com/firebase/genkit/go/ai"

	"golang.org/x/net/html"
)

const jobLogsURLTemplate = "https://logserver.rdoproject.org/%s/rdoproject.org/%s/"

type DirCrawlerToolInput struct {
	JobID string
}

// processFile single HTML <tr> element containing single file data. It either appends text file urls
// or recursively nests to directory(ies) and collects text files' urls there.
func processFile(n *html.Node, dirURL string) ([]string, error) {
	//<tr><td><img alt="[PARENTDIR]|[DIR]|[TXT]|[   ]"></td><td><a href="...">filename</a></td><td></td><td></td></tr>
	files := []string{}
	fileType := ""
	for i := n.FirstChild; i != nil; i = i.NextSibling {
		if i.Type == html.ElementNode && i.Data == "td" {
			for c := i.FirstChild; c != nil; c = c.NextSibling {
				if c.Type == html.ElementNode {
					switch c.Data {
					case "img":
						for _, a := range c.Attr {
							if a.Key == "alt" {
								fileType = a.Val
							}
						}
					case "a":
						fileURL := ""
						for _, a := range c.Attr {
							if a.Key == "href" {
								fileURL = dirURL + a.Val
							}
						}

						if fileType == "[DIR]" {
							fls, err := processDirectory(fileURL)
							if err != nil {
								return nil, err
							}
							files = append(files, fls...)
						}
						if fileType == "[TXT]" {
							files = append(files, fileURL)
						}
					}
				}
			}
		}
	}
	return files, nil
}

// processDirectoty recursively goes through each file item and collects all the text files' urls
func processDirectory(dirURL string) ([]string, error) {
	files := []string{}

	resp, err := http.Get(dirURL)
	if err != nil {
		return nil, err
	}
	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		return nil, nil
	}

	rootDoc, err := html.Parse(resp.Body)
	if err != nil {
		return nil, fmt.Errorf("failed to parse root document")
	}

	var processAllFiles func(*html.Node) error
	processAllFiles = func(n *html.Node) error {
		if n.Type == html.ElementNode && n.Data == "tr" {
			fls, err := processFile(n, dirURL)
			if err != nil {
				return fmt.Errorf("failed to parse file item: %w", err)
			}
			files = append(files, fls...)
		}
		for c := n.FirstChild; c != nil; c = c.NextSibling {
			if err := processAllFiles(c); err != nil {
				return err
			}
		}
		return nil
	}
	err = processAllFiles(rootDoc)
	return files, nil
}

// DirCrawlerTool returns a tool function that returns list of log files generated by certain CI job identified by job ID.
func DirCrawlerTool() func(ctx *ai.ToolContext, input DirCrawlerToolInput) ([]string, error) {
	return func(ctx *ai.ToolContext, input DirCrawlerToolInput) ([]string, error) {
		jobURL := fmt.Sprintf(jobLogsURLTemplate, input.JobID[:3], input.JobID)

		return processDirectory(jobURL)
	}
}
